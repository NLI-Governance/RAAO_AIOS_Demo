import json
import openai
from aios_secrets.openai_key import openai_api_key
from tools.query_policy_rag_synonyms import normalize_query, expand_with_synonyms

openai.api_key = openai_api_key

def get_policy_answer(expanded_query_dict: dict) -> str:
    try:
        # Try static fallback first
        with open("data/policies/lookup_aids/rag_fallback_topics.json", "r") as f:
            fallback_topics = json.load(f)

        for eq in expanded_query_dict["expanded_queries"]:
            if eq.lower() in fallback_topics:
                return fallback_topics[eq.lower()]  # Found static match

        # If not found, use GPT fallback
        expanded_text = expanded_query_dict["expanded_queries"]
        prompt = "üß† You are a policy assistant.\n\n"
        prompt += f"The user asked: '{expanded_query_dict['original']}'\n\n"
        prompt += "The normalized and expanded queries include:\n"
        for i, q in enumerate(expanded_text):
            prompt += f"- {q}\n"
        prompt += "\nPlease provide a helpful, respectful answer based on workplace policy assumptions."

        # GPT fallback (OpenAI SDK v0.28.1 format)
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a helpful HR policy assistant."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=300,
            temperature=0.3
        )

        # Old SDK requires choices[0].message['content']
        gpt_reply = response["choices"][0]["message"]["content"].strip()
        return gpt_reply

    except Exception as e:
        return f"‚ö†Ô∏è GPT fallback failed: {e}"
